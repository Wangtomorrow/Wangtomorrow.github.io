<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Olicity Forever</title>
  
  <subtitle>菜鸡与代码的日常</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://wangtomorrow.github.io/"/>
  <updated>2018-10-11T06:18:59.799Z</updated>
  <id>https://wangtomorrow.github.io/</id>
  
  <author>
    <name>Olicity</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>关于hadoop3.0的使用</title>
    <link href="https://wangtomorrow.github.io/post/f9a72d3.html"/>
    <id>https://wangtomorrow.github.io/post/f9a72d3.html</id>
    <published>2018-10-10T11:00:07.000Z</published>
    <updated>2018-10-11T06:18:59.799Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;总算是有点时间了，捣鼓一下hadoop3.0的一些东西，听说3.0比spark快十倍？<br><a id="more"></a></p><h2 id="一、安装配置"><a href="#一、安装配置" class="headerlink" title="一、安装配置"></a>一、安装配置</h2><p>&emsp;前面的环境配置与解压安装大体一致。配置文件的异同如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line">1.集群节点配置文件</span><br><span class="line">    3.0以前都是通过 安装目录/etc/hadoop/slaves 进行配置，3.0则是在同一目录下的workers配置，改个名?具体的配置方式与之前一样，每行一个节点名。</span><br><span class="line">2.hadoop-env.sh</span><br><span class="line">    之前只需配置此文件下的JAVA_HOME,现在除了必要的JAVA_HOME外还需修改如下：</span><br><span class="line">    export JAVA_HOME=/usr/local/java/jdk1.8.0_65</span><br><span class="line">    export HADOOP_HOME=/usr/local/hadoop/hadoop-3.1.1</span><br><span class="line">    export HDFS_NAMENODE_USER=root</span><br><span class="line">    export HDFS_DATANODE_USER=root</span><br><span class="line">    export HDFS_SECONDARYNAMENODE_USER=root</span><br><span class="line">    export YARN_RESOURCEMANAGER_USER=root</span><br><span class="line">    export YARN_NODEMANAGER_USER=root</span><br><span class="line">    就是配置你的hadoop用户。我是配置的root，如果配置个别用户的话，自行更改。</span><br><span class="line">3.core-site.xml</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">      &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">     &lt;!-- 指定hdfs的namenode的通信地址 --&gt;</span><br><span class="line">      &lt;value&gt;hdfs://192.168.2.100:9000&lt;/value&gt;</span><br><span class="line">     &lt;/property&gt;</span><br><span class="line">     &lt;property&gt;</span><br><span class="line">      &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">        &lt;!-- 以下为存放临时文件的路径 --&gt;</span><br><span class="line">      &lt;value&gt;/home/olicity/hadoop/tmp&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    与之前版本一致</span><br><span class="line">4.hdfs-site.xml</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">       &lt;name&gt;dfs.name.dir&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;/home/olicity/hadoop/dfs/name&lt;/value&gt;</span><br><span class="line">       &lt;description&gt;Path on the local filesystem where theNameNode stores the namespace and transactions logs persistently.&lt;/description&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">       &lt;name&gt;dfs.data.dir&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;/home/olicity/hadoop/dfs/data&lt;/value&gt;</span><br><span class="line">       &lt;description&gt;Comma separated list of paths on the localfilesystem of a DataNode where it should store its blocks.&lt;/description&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.http-address&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;centos0:50070&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;centos0:50090&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">       &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">       &lt;value&gt;2&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">          &lt;name&gt;dfs.permissions&lt;/name&gt;</span><br><span class="line">          &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">          &lt;description&gt;need not permissions&lt;/description&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    无差。</span><br><span class="line">5.yarn-site.xml</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;centos0&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">      &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;</span><br><span class="line">     &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt;</span><br><span class="line">    &lt;!-- cpu个数 需要根据当前机器cpu设置 --&gt;</span><br><span class="line">        &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    关于cpu的配置，记得之前看过2.2版本就提出过一个初步的实现方式，之前一直没配置过，3.0试一下。</span><br><span class="line">6.mapred-site.xml</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;mapred.job.tracker&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;centos0:49001&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">          &lt;name&gt;mapred.local.dir&lt;/name&gt;</span><br><span class="line">           &lt;value&gt;/home/olicity/hadoop/var&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    </span><br><span class="line">    &lt;property&gt;</span><br><span class="line">           &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">           &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    大同小异。其实只要配置mapreduce.framework.name也行。</span><br></pre></td></tr></table></figure></p><p>&emsp;总体来看配置方面除了slave改名为worker和hadoop-env.xml配置用户外，别的地方都大同小异。<br>&emsp;接下来就是初始化同样的命令 hdfs namenode -format 。注意要是配置的root用户需要使用root用户进行初始化。同样，不报错返回“Exiting with status 0”即为成功。然后就是在namenode上start-all.sh或者dfs与yarn分开启动也行。最后在集群每台机器上分别jps查看进程启动情况。<br>&emsp;还有之前看过别人的配置，他在hadoop-env.xml下并没有配置用户，而是写在每个start-*.sh脚本中了。</p><h2 id="二、文档和大佬们总结的变化"><a href="#二、文档和大佬们总结的变化" class="headerlink" title="二、文档和大佬们总结的变化"></a>二、文档和大佬们总结的变化</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">1.最低Java版本要求从Java7变为Java8  </span><br><span class="line">2.HDFS支持纠删码（erasure coding）</span><br><span class="line">    用来解决存储空间文件。EC技术既可以防止数据丢失，又能解决HDFS存储空间翻倍的问题。使得HDFS在不降低可靠性的前提下，节省一半存储空间。</span><br><span class="line">    另外，在使用这个新特性时，用户还需要考虑网络和CPU开销。</span><br><span class="line">3.YARN的时间线V.2服务</span><br><span class="line">    提高时间线服务的可伸缩性和可靠性，通过引入流和聚合来增强可用性</span><br><span class="line">    具体的一些原理和操作，还是看官方文档和大佬博客吧。</span><br><span class="line">4.优化Hadoop Shell脚本，除了修复一些bug，还加入一些新特性</span><br><span class="line">5.精简了内核，剔除了过期的API和实现，废弃hftp转由webhdfs替代。重构Hadoop Client Jar包，解决jar包冲突问题</span><br><span class="line">6.支持等待容器和分布式调度</span><br><span class="line">    在Hadoop3 中引入了一种新型执行类型，即等待容器，即使在调度时集群没有可用的资源，它也可以在NodeManager中被调度执行。在这种情况下，这些容器将在NM中排队等待资源启动，等待荣容器比默认容器优先级低，因此，如果需要，可以抢占默认容器的空间，这样可以提供机器的利用率。</span><br><span class="line">7.MapReduce任务级别本地化优化</span><br><span class="line">    MapReduce添加了映射输出收集器的本地化实现的支持。对于密集型的洗牌操作（shuffle-intensive）jobs，可以带来30%的性能提升。</span><br><span class="line">8.支持多个NameNode节点</span><br><span class="line">    namenode的高可用性</span><br><span class="line">9.修改了多重服务的默认端口</span><br><span class="line">    防止端口冲突</span><br><span class="line">10.提供文件系统连接器（filesystem connnector）,支持Microsoft Azure Data Lake和Aliyun对象存储系统</span><br><span class="line">11.数据节点内置平衡器</span><br><span class="line">    通过hdfs diskbalancer ClI来调用，解决单一DataNode管理多个磁盘情况下，添加或删除磁盘导致磁盘负载不均衡问题</span><br><span class="line">12.重写了守护进程和任务的堆管理机制</span><br><span class="line">    现在可以根据主机的内存大小进行自动调整，并且已经禁止HADOOP_HEAPSIZE变量</span><br><span class="line">    Map和Reduce的堆大小的配置被简化了，所以不再需要任务配置作为一个Java选项指定。已经指定的两个现有配置不受此更改的影响</span><br><span class="line">13.S3Gurad:为S3A文件系统客户端提供一致性和元数据缓存</span><br><span class="line">14.HDFS的基于路由器互联</span><br><span class="line">    HDFS Router-Based Federation添加了一个RPC路由层，为多个HDFS命名空间提供了一个联合视图。简化了现存HDFS客户端接入federated cluster的操作。</span><br><span class="line">15.基于API配置的Capacity Scheduler queue configuration</span><br><span class="line">16.YARN资源类型</span><br><span class="line">    Yarn资源模型已经被一般化，可以支持用户自定义的可计算资源类型，而不仅仅是CPU和内存。比如，集群管理员可以定义像GPU数量，软件序列号、本地连接的存储的资源。然后，Yarn任务能够在这些可用资源上进行调度。</span><br></pre></td></tr></table></figure><p>&emsp;差不多就这些，很多东西我还没细入研究过，主要看的是几处大的变动和效率的优化。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">以下是hadoop-3.0的最新参数</span><br><span class="line">Hadoop-3.0</span><br><span class="line">· HADOOP</span><br><span class="line">    · Move to JDK8+</span><br><span class="line">    · Classpath isolation on by default HADOOP-11656</span><br><span class="line">    · Shell script rewrite HADOOP-9902</span><br><span class="line">    · Move default ports out of ephemeral range HDFS-9427</span><br><span class="line">· HDFS</span><br><span class="line">    · Removal of hftp in favor of webhdfs HDFS-5570</span><br><span class="line">    · Support for more than two standby NameNodes HDFS-6440</span><br><span class="line">    · Support for Erasure Codes in HDFS HDFS-7285</span><br><span class="line">· YARN</span><br><span class="line">· MAPREDUCE</span><br><span class="line">    · Derive heap size or mapreduce.*.memory.mb automatically MAPREDUCE-5785</span><br></pre></td></tr></table></figure></p><h2 id="三、使用"><a href="#三、使用" class="headerlink" title="三、使用"></a>三、使用</h2><p>&emsp;暂时还没在项目上使用，就简单写了个单词划分测试，具体效率的提升还是参照<a href="https://blog.csdn.net/u011610826/article/details/79026022" target="_blank" rel="noopener">Hadoop3.0版本安装、性能研究</a></p><h2 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h2><p>&emsp;目前已经自己模拟搭建并跑起来了一个四台机器组成的集群，下一步准备捣鼓捣鼓源码那块吧，使用hadoop跑点实际应用的东西，还在筹划中。</p><h2 id="五、相关链接"><a href="#五、相关链接" class="headerlink" title="五、相关链接"></a>五、相关链接</h2><p>感谢一下几位大佬的博客：</p><ul><li><a href="https://blog.csdn.net/yongge1981/article/details/80504935" target="_blank" rel="noopener">Hadoop 3相对于hadoop2的 新特性</a></li><li><a href="https://www.cnblogs.com/smartloli/p/8827623.html" target="_blank" rel="noopener">Hadoop 3.x 新特性剖析系列</a></li><li><a href="https://blog.csdn.net/u011610826/article/details/79026022" target="_blank" rel="noopener">Hadoop3.0版本安装、性能研究</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;总算是有点时间了，捣鼓一下hadoop3.0的一些东西，听说3.0比spark快十倍？&lt;br&gt;
    
    </summary>
    
    
      <category term="hadoop" scheme="https://wangtomorrow.github.io/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>通过配置application.yml实现开发测试生产环境的搭建</title>
    <link href="https://wangtomorrow.github.io/post/5c4ace42.html"/>
    <id>https://wangtomorrow.github.io/post/5c4ace42.html</id>
    <published>2018-09-29T08:47:18.000Z</published>
    <updated>2018-10-11T06:27:22.233Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;前几天由于开发与测试用的是同一个系统，开发的时候测试不能使用，通过application.yml来控制不同环境。<br><a id="more"></a></p><h2 id="一、系统设计"><a href="#一、系统设计" class="headerlink" title="一、系统设计"></a>一、系统设计</h2><p><img src="https://github.com/Wangtomorrow/Resource/blob/master/application.png?raw=true" alt="系统设计图"><br>系统设计如图，公共服务可以放到一起，容易产生冲突的服务单独搭建为私有服务。图片未加载出来，<a href="https://github.com/Wangtomorrow/Resource/blob/master/application.png?raw=true" target="_blank" rel="noopener">点击</a></p><h2 id="二、application-yml"><a href="#二、application-yml" class="headerlink" title="二、application.yml"></a>二、application.yml</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">spring:</span><br><span class="line">  profiles:</span><br><span class="line">    active: dev //在此控制不同环境的入口（开发：dev， 测试：test， 生产：prod）</span><br></pre></td></tr></table></figure><h2 id="三、application-dev-yml"><a href="#三、application-dev-yml" class="headerlink" title="三、application-dev.yml"></a>三、application-dev.yml</h2><p>大部分配置都是相同的就行。<br>涉及到数据库或者别的公用的东西，产生冲突的分别单独搭建。<br>通过配置profile的active属性即可<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">spring:</span><br><span class="line">  profiles:</span><br><span class="line">    active: dev</span><br></pre></td></tr></table></figure></p><p>&emsp;这样就可以一套代码部署到不同环境上，开发测试生产互不干扰。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;前几天由于开发与测试用的是同一个系统，开发的时候测试不能使用，通过application.yml来控制不同环境。&lt;br&gt;
    
    </summary>
    
    
      <category term="application.yml" scheme="https://wangtomorrow.github.io/tags/application-yml/"/>
    
      <category term="环境搭建" scheme="https://wangtomorrow.github.io/tags/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
  </entry>
  
  <entry>
    <title>Kafka及Spring&amp;Kafka整合</title>
    <link href="https://wangtomorrow.github.io/post/85675a3e.html"/>
    <id>https://wangtomorrow.github.io/post/85675a3e.html</id>
    <published>2018-09-13T08:05:01.000Z</published>
    <updated>2018-09-13T10:33:06.615Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;由于某项目的消息队列使用了Spring整合Kafka，开发中我需要使用kafka客户端模拟生产者和消费者。简单了解了一下Kafka，扫盲贴，先标记一下，日后再深入学习。<br><a id="more"></a></p><h2 id="一、Kafka简介"><a href="#一、Kafka简介" class="headerlink" title="一、Kafka简介"></a>一、Kafka简介</h2><h3 id="1-1-简介"><a href="#1-1-简介" class="headerlink" title="1.1 简介"></a>1.1 简介</h3><p>&emsp; kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的网站中的所有动作流数据。这种动作（网页浏览，搜索和其他用户的行动）是在现代网络上的许多社会功能的一个关键因素。这些数据通常是由于吞吐量的要求而通过处理日志和日志聚合来解决。<br>&emsp;在大数据系统中，常常会碰到一个问题，整个大数据是由各个子系统组成，数据需要在各个子系统中高性能，低延迟的不停流转。传统的企业消息系统并不是非常适合大规模的数据处理。为了已在同时搞定在线应用（消息）和离线应用（数据文件，日志）Kafka就出现了。<br>&emsp;简单点概括一下：Kafka是一个分布式的，可划分的，高性能，低延迟的，冗余备份的持久性的日志服务。它主要用于处理活跃的流式数据。</p><h3 id="1-2-特点"><a href="#1-2-特点" class="headerlink" title="1.2 特点"></a>1.2 特点</h3><pre><code>* 高吞吐量* 可进行持久化操作* 分布式</code></pre><h3 id="1-3-组件"><a href="#1-3-组件" class="headerlink" title="1.3 组件"></a>1.3 组件</h3><p>&emsp;Topic，Broker，Partition，Message，Producer，Consumer,Zookpeer</p><h4 id="1-3-1-名词解释"><a href="#1-3-1-名词解释" class="headerlink" title="1.3.1 名词解释"></a>1.3.1 名词解释</h4><pre><code>服务：Topic：主题，Kafka处理的消息的不同分类。Broker：消息代理，Kafka集群中的一个kafka服务节点称为一个broker，主要存储消息数据。存在硬盘中。每个topic都是有分区的。Partition：Topic物理上的分组，一个topic在broker中被分为1个或者多个partition，分区在创建topic的时候指定。Message：消息，是通信的基本单位，每个消息都属于一个partition服务相关：Producer：消息和数据的生产者，向Kafka的一个topic发布消息。Consumer：消息和数据的消费者，定于topic并处理其发布的消息。Zookeeper：协调kafka的正常运行。</code></pre><h3 id="1-4-应用场景"><a href="#1-4-应用场景" class="headerlink" title="1.4 应用场景"></a>1.4 应用场景</h3><p>构建实时的流数据管道，可靠地获取系统和应用程序之间的数据。<br>构建实时流的应用程序，对数据流进行转换或反应。  </p><h2 id="二、Kafka搭建"><a href="#二、Kafka搭建" class="headerlink" title="二、Kafka搭建"></a>二、Kafka搭建</h2><h3 id="2-1-安装"><a href="#2-1-安装" class="headerlink" title="2.1 安装"></a>2.1 安装</h3><p>&emsp;教程很多，就不写了。 </p><h3 id="2-2-配置"><a href="#2-2-配置" class="headerlink" title="2.2 配置"></a>2.2 配置</h3><p>&emsp;配置文件放在kafka下config下</p><pre><code>* consumer.properites 消费者配置* producer.properties 生产者配置* server.properties kafka服务器的配置    broker.id 申明当前kafka服务器在集群中的唯一ID，需配置为integer,并且集群中的每一个kafka服务器的id都应是唯一的    listeners 申明此kafka服务器需要监听的端口号，如果是在本机上跑虚拟机运行可以不用配置本项，默认会使用localhost的地址，如果是在远程服务器上运行则必须配置，例如：              listeners=PLAINTEXT:// 192.168.180.128:9092。并确保服务器的9092端口能够访问    zookeeper.connect 申明kafka所连接的zookeeper的地址 ，需配置为zookeeper的地址</code></pre><p>&emsp;上面配置文件中listeners的配置尤其注意，刚开始整的时候，没注意自己编写producer和cusmer时报错，如下：</p><pre><code>Connection to node -1 could not be established. Broker may not be available.</code></pre><p>&emsp;就是因为配置文件中的PLAINTEXT跟我请求的内容不同。</p><p>&emsp;具体配置教程很多，也不写了。</p><h2 id="三、Kafka操作"><a href="#三、Kafka操作" class="headerlink" title="三、Kafka操作"></a>三、Kafka操作</h2><h3 id="3-1-Topic操作"><a href="#3-1-Topic操作" class="headerlink" title="3.1 Topic操作"></a>3.1 Topic操作</h3><h4 id="3-1-1-创建Topic"><a href="#3-1-1-创建Topic" class="headerlink" title="3.1.1 创建Topic"></a>3.1.1 创建Topic</h4><pre><code>kafka-topics.sh --create --topic hbase --zookeeper ip1:port --partitions 3 --replication-factor 1创建topic过程的问题，replication-factor个数不能超过broker的个数创建topic后，可以在../data/kafka目录查看到分区的目录</code></pre><h4 id="3-1-2-查看Topic列表"><a href="#3-1-2-查看Topic列表" class="headerlink" title="3.1.2 查看Topic列表"></a>3.1.2 查看Topic列表</h4><pre><code>kafka-topics.sh --list --zookeeper ip:port</code></pre><h4 id="3-1-3-查看某一个具体的Topic"><a href="#3-1-3-查看某一个具体的Topic" class="headerlink" title="3.1.3 查看某一个具体的Topic"></a>3.1.3 查看某一个具体的Topic</h4><pre><code>kafka-topics.sh --describe xxx --zookeeper ip:port</code></pre><h4 id="3-1-4-修改Topic"><a href="#3-1-4-修改Topic" class="headerlink" title="3.1.4 修改Topic"></a>3.1.4 修改Topic</h4><pre><code>kafka-topics.sh --alter --topic topic-test --zookeeper ip:port --partitions 3不能修改replication-factor，以及只能对partition个数进行增加，不能减少</code></pre><h4 id="3-1-5-删除Topic"><a href="#3-1-5-删除Topic" class="headerlink" title="3.1.5 删除Topic"></a>3.1.5 删除Topic</h4><pre><code>kafka-topics.sh --delete --topic topic-test --zookeeper ip:port彻底删除一个topic，需要在server.properties中配置delete.topic.enable=true，否则只是标记删除配置完成之后，需要重启kafka服务。</code></pre><h3 id="3-2-生产者操作"><a href="#3-2-生产者操作" class="headerlink" title="3.2 生产者操作"></a>3.2 生产者操作</h3><pre><code>sh kafka-console-producer.sh --broker-list ip1:port,ip2:port,ip3:port --sync --topic kafka-topic-test生产数据的时候需要指定：当前数据流向哪个broker，以及哪一个topic</code></pre><h3 id="3-3-消费者操作"><a href="#3-3-消费者操作" class="headerlink" title="3.3 消费者操作"></a>3.3 消费者操作</h3><pre><code>sh kafka-console-consumer.sh --zookeeper ip1:port,ip2:port,ip3:port --topic kafka-topic-test --from-beginning--from-begining 获取最新以及历史数据黑白名单（暂时未用到）--blacklist 后面跟需要过滤的topic的列表，使用&quot;,&quot;隔开，意思是除了列表中的topic之外，都能接收其它topic的数据--whitelist 后面跟需要过滤的topic的列表，使用&quot;,&quot;隔开，意思是除了列表中的topic之外，都不能接收其它topic的数据</code></pre><h2 id="四、Springboot整合Kafka"><a href="#四、Springboot整合Kafka" class="headerlink" title="四、Springboot整合Kafka"></a>四、Springboot整合Kafka</h2><p>这个只是个人使用的简单的测试环境搭建，可能有很多地方有问题，以后深入学习时再检查。</p><h3 id="4-1-整合"><a href="#4-1-整合" class="headerlink" title="4.1 整合"></a>4.1 整合</h3><p>&emsp;springboot集成kafka的默认配置都在org.springframework.boot.autoconfigure.kafka包里面。直接使用即可。flag=深入学习kafka。</p><h3 id="4-2-pom-xml配置"><a href="#4-2-pom-xml配置" class="headerlink" title="4.2 pom.xml配置"></a>4.2 pom.xml配置</h3><pre><code>&lt;dependency&gt;   &lt;!--引入spring和kafka整合的jar--&gt;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;            &lt;artifactId&gt;spring-cloud-starter-stream-kafka&lt;/artifactId&gt;            &lt;exclusions&gt;                &lt;exclusion&gt;                    &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;                    &lt;artifactId&gt;kafka_2.11&lt;/artifactId&gt;                &lt;/exclusion&gt;                &lt;exclusion&gt;                    &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;                    &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;                &lt;/exclusion&gt;                &lt;exclusion&gt;                    &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt;                    &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;                &lt;/exclusion&gt;            &lt;/exclusions&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;            &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;            &lt;artifactId&gt;kafka_2.11&lt;/artifactId&gt;            &lt;version&gt;1.0.1&lt;/version&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt;            &lt;artifactId&gt;spring-cloud-task-core&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt;            &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;            &lt;version&gt;1.3.5.RELEASE&lt;/version&gt;&lt;!--$NO-MVN-MAN-VER$--&gt;            &lt;/dependency&gt;        &lt;dependency&gt;</code></pre><h3 id="4-3-Producer配置"><a href="#4-3-Producer配置" class="headerlink" title="4.3 Producer配置"></a>4.3 Producer配置</h3><pre><code>@Configuration@EnableKafkapublic class KafkaProducer {    public Map&lt;String, Object&gt; producerConfigs() {        Map&lt;String, Object&gt; props = new HashMap&lt;&gt;();        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, KafkaConfig.BOOTSTRAP_SERVERS);        props.put(ProducerConfig.RETRIES_CONFIG, KafkaConfig.PRODUCER_RETRIES);        props.put(ProducerConfig.BATCH_SIZE_CONFIG, KafkaConfig.PRODUCER_BATCH_SIZE);        props.put(ProducerConfig.LINGER_MS_CONFIG, KafkaConfig.PRODUCER_LINGER_MS);        props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, KafkaConfig.PRODUCER_BUFFER_MEMORY);        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);        props.put(&quot;advertised.host.name&quot;,KafkaConfig.BOOTSTRAP_SERVERS);        props.put(ConsumerConfig.GROUP_ID_CONFIG, &quot;1&quot;);        System.out.println(&quot;KafkaConfig.BOOTSTRAP_SERVERS:&quot;+KafkaConfig.BOOTSTRAP_SERVERS);        return props;    }    /** 获取工厂 */    public ProducerFactory&lt;String, String&gt; producerFactory() {        return new DefaultKafkaProducerFactory&lt;&gt;(producerConfigs());    }    /** 注册实例 */    @Bean    public KafkaTemplate&lt;String, String&gt; kafkaTemplate() {        return new KafkaTemplate&lt;&gt;(producerFactory());    }}</code></pre><h3 id="4-4-使用生产者"><a href="#4-4-使用生产者" class="headerlink" title="4.4 使用生产者"></a>4.4 使用生产者</h3><pre><code>@Autowiredprivate KafkaTemplate&lt;String, String&gt; kafkaTemplate;kafkaTemplate.send(&quot;kafka-topic-test&quot;, &quot;helloWorld&quot;);</code></pre><h3 id="4-5-Consumer配置"><a href="#4-5-Consumer配置" class="headerlink" title="4.5 Consumer配置"></a>4.5 Consumer配置</h3><pre><code>@Configuration@EnableKafkapublic class KafkaConsumer {    private final static Logger log = LoggerFactory.getLogger(KafkaConsumer .class);    @KafkaListener(topics = {&quot;kafka-topic-test&quot;})    public void consume(ConsumerRecord&lt;?, ?&gt; record) {        String topic = record.topic();        String value = record.value().toString();        System.out.println(&quot;partitions:&quot;+record.partition()+&quot;,&quot;+&quot;offset:&quot;+record.offset()+&quot;,value=&quot;+value);        MqConsumerRunnable runnable = new MqConsumerRunnable(topic,value);        executor.execute(runnable);    }    public Map&lt;String, Object&gt; consumerConfigs() {        Map&lt;String, Object&gt; props = new HashMap&lt;&gt;();        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, KafkaConfig.BOOTSTRAP_SERVERS);        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, true);        props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, &quot;100&quot;);        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);        props.put(ConsumerConfig.GROUP_ID_CONFIG, &quot;1&quot;);        props.put(&quot;auto.offset.reset&quot;, &quot;latest&quot;);// 一般配置earliest 或者latest 值        return props;    }    /** 获取工厂 */    public ConsumerFactory&lt;String, String&gt; consumerFactory() {        return new DefaultKafkaConsumerFactory&lt;&gt;(consumerConfigs());    }    /** 获取实例 */    @Bean    public KafkaListenerContainerFactory&lt;ConcurrentMessageListenerContainer&lt;String, String&gt;&gt; kafkaListenerContainerFactory() {        ConcurrentKafkaListenerContainerFactory&lt;String, String&gt; factory = new ConcurrentKafkaListenerContainerFactory&lt;&gt;();        factory.setConsumerFactory(consumerFactory());        factory.setConcurrency(3);        factory.getContainerProperties().setPollTimeout(3000);        return factory;    }}</code></pre><h3 id="4-6-使用消费者"><a href="#4-6-使用消费者" class="headerlink" title="4.6 使用消费者"></a>4.6 使用消费者</h3><pre><code>public class KafkaMessageListener implements MessageListener&lt;String, String&gt; {    private static Logger LOG = LoggerFactory.getLogger(KafkaMessageListener.class);    @Autowired    private AppProperties appProperties;    @Override    public void onMessage(ConsumerRecord&lt;String, String&gt; data) {        LOG.info(&quot;消费消息topic：{} value {}&quot;, data.topic(), data.value());        String topic = data.topic();        String content = data.value();        //可同时监听多个topic，根据不同topic处理不同的业务        if (topic.equals(&quot;topica&quot;)) {                       LOG.info(&quot;###############topic:{} value:{}&quot; ,topic,content);        } else if (topic.equals(&quot;topicb&quot;)) {         LOG.info(&quot;###############topic:{} value:{}&quot; ,topic,content);        }     }}</code></pre><h3 id="4-7-注意"><a href="#4-7-注意" class="headerlink" title="4.7 注意"></a>4.7 注意</h3><pre><code>kafkaTemplate.send(&quot;kafka-topic-test&quot;, &quot;helloWorld&quot;);@KafkaListener(topics = {&quot;kafka-topic-test&quot;})topic需要对应</code></pre><h4 id="4-8-使用"><a href="#4-8-使用" class="headerlink" title="4.8 使用"></a>4.8 使用</h4><p>&emsp;本地运行以后，到kafka服务器上可以进行消费者和生产者的模拟发送与接收信息。</p><h2 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h2><p>&emsp;上述方法进行模拟测试，可以测试，但是总感觉问题很大，却又找不出问题，这个后期再说吧，先凑合用。<br>&emsp;有关Kafka的具体学习，后期补上。</p><h2 id="六、相关链接"><a href="#六、相关链接" class="headerlink" title="六、相关链接"></a>六、相关链接</h2><p>感谢各位大佬：</p><ul><li><a href="https://www.cnblogs.com/yangxiaoyi/p/7359236.html" target="_blank" rel="noopener">kafka 基础知识梳理</a></li><li><a href="https://www.cnblogs.com/hei12138/p/7805475.html" target="_blank" rel="noopener">kafka实战</a></li><li><a href="http://blog.51cto.com/xpleaf/2090847" target="_blank" rel="noopener">kafka笔记整理</a></li><li><a href="https://www.cnblogs.com/yepei/p/6197236.html" target="_blank" rel="noopener">kafka介绍</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;由于某项目的消息队列使用了Spring整合Kafka，开发中我需要使用kafka客户端模拟生产者和消费者。简单了解了一下Kafka，扫盲贴，先标记一下，日后再深入学习。&lt;br&gt;
    
    </summary>
    
    
      <category term="Kafka" scheme="https://wangtomorrow.github.io/tags/Kafka/"/>
    
      <category term="Springboot Kafka" scheme="https://wangtomorrow.github.io/tags/Springboot-Kafka/"/>
    
      <category term="笔记" scheme="https://wangtomorrow.github.io/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>spring学习记录(一)</title>
    <link href="https://wangtomorrow.github.io/post/61f45dcf.html"/>
    <id>https://wangtomorrow.github.io/post/61f45dcf.html</id>
    <published>2018-09-11T06:45:18.000Z</published>
    <updated>2018-09-14T09:12:56.086Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;最近在做后端的开发，用到了spring，借这个机会给spring捋一遍吧。东西有点多，需要点时间，抽空学。记录(一)主要是写一点spring最基础的IOC和AOP,至于spring的各种注解和SpingMVC另开贴。<br><a id="more"></a></p><h2 id="一、Spring概述"><a href="#一、Spring概述" class="headerlink" title="一、Spring概述"></a>一、Spring概述</h2><h3 id="1-简介"><a href="#1-简介" class="headerlink" title="1.简介"></a>1.简介</h3><p>&emsp;Spring是一个基于 <strong>控制反转（IOC）</strong> 和 <strong>面向切面（AOP）</strong> 的结构J2EE系统的框架。从简单性、可测试性和松耦合的角度而言，任何Java应用都可以从Spring中受益。<br>&emsp;控制反转(IOC)是一个通用概念，Spring最认同的技术是控制反转的 <strong>依赖注入（DI）</strong> 模式。简单地说就是拿到的对象的属性，已经被注入好相关值了，直接使用即可。<br>&emsp;面向切面编程（AOP），一个程序中跨越多个点的功能被称为横切关注点，这些横切关注点在概念上独立于应用程序的业务逻辑。Spring 框架的 AOP 模块提供了面向方面的程序设计实现，可以定义诸如方法拦截器和切入点等，从而使实现功能的代码彻底的解耦出来。  </p><h3 id="2-Spring关键策略"><a href="#2-Spring关键策略" class="headerlink" title="2.Spring关键策略"></a>2.Spring关键策略</h3><pre><code>* 基于POJO的轻量级和最小侵入性编程* 通过依赖注入和面向接口实现松耦合* 基于切面和惯例进行声明式编程* 通过切面和模板减少样板式代码</code></pre><h3 id="3-Spring优点"><a href="#3-Spring优点" class="headerlink" title="3.Spring优点"></a>3.Spring优点</h3><pre><code>*方便解耦，简化开发 （高内聚低耦合）     Spring就是一个大工厂（容器），可以将所有对象创建和依赖关系维护，交给Spring管理     spring工厂是用于生成bean*AOP编程的支持     Spring提供面向切面编程，可以方便的实现对程序进行权限拦截、运行监控等功能    声明式事务的支持     只需要通过配置就可以完成对事务的管理，而无需手动编程*方便程序的测试     Spring对Junit4支持，可以通过注解方便的测试Spring程序*方便集成各种优秀框架     Spring不排斥各种优秀的开源框架，其内部提供了对各种优秀框架（如：Struts、Hibernate、MyBatis、Quartz等）的直接支持*降低JavaEE API的使用难度     Spring 对JavaEE开发中非常难用的一些API（JDBC、JavaMail、远程调用等），都提供了封装，使这些API应用难度大大降低</code></pre><h2 id="二、控制反转（IOC）"><a href="#二、控制反转（IOC）" class="headerlink" title="二、控制反转（IOC）"></a>二、控制反转（IOC）</h2><h3 id="1-概述"><a href="#1-概述" class="headerlink" title="1.概述"></a>1.概述</h3><p>&emsp;代码之间的 <strong>耦合性</strong> 具有两面性。耦合是必须的，但应小心谨慎的管理。<br>&emsp;DI会将所以来的关系自动交给目标对象，而不是让对象自己去获取依赖。– <strong>松耦合</strong></p><h3 id="2-获取对象的方式进行比较"><a href="#2-获取对象的方式进行比较" class="headerlink" title="2.获取对象的方式进行比较"></a>2.获取对象的方式进行比较</h3><p>传统方式：<br>通过new关键字主动创建一个对象<br>IOC方式：<br>对象的生命周期由Spring来管理，直接从Spring那里去获取一个对象。 IOC是反转控制 (Inversion Of Control)的缩写，就像控制权从本来在自己手里，交给了Spring。</p><h3 id="3-装配"><a href="#3-装配" class="headerlink" title="3.装配"></a>3.装配</h3><p>&emsp;创建应用组件之间协作的行为通常称为装配。常用XML装配方式。Spring配置文件。</p><pre><code class="xml">*使用构造器进行配置    <span class="tag">&lt;<span class="name">bean</span>&gt;</span> 定义JavaBean，配置需要创建的对象    id/name ：用于之后从spring容器获得实例时使用的    class ：需要创建实例的全限定类名    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">"c"</span> <span class="attr">class</span>=<span class="string">"pojo.Category"</span>&gt;</span>        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"name"</span> <span class="attr">value</span>=<span class="string">"category 1"</span> /&gt;</span> <span class="comment">&lt;!--category对象--&gt;</span>    <span class="tag">&lt;/<span class="name">bean</span>&gt;</span>    <span class="comment">&lt;!--创建product对象的时候注入了一个category对象，使用ref--&gt;</span>    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">name</span>=<span class="string">"p"</span> <span class="attr">class</span>=<span class="string">"pojo.Product"</span>&gt;</span> <span class="comment">&lt;!--product类中添加category对象的set&amp;get方法--&gt;</span>        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"name"</span> <span class="attr">value</span>=<span class="string">"product1"</span> /&gt;</span>   <span class="comment">&lt;!--product对象--&gt;</span>        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">"category"</span> <span class="attr">ref</span>=<span class="string">"c"</span> /&gt;</span>    <span class="comment">&lt;!--为product对象注入category对象--&gt;</span>    <span class="tag">&lt;/<span class="name">bean</span>&gt;</span>*使用注解的方式进行配置    xml中添加  <span class="tag">&lt;<span class="name">context:annotation-config</span>/&gt;</span> 注释掉注入category        *@Autowired注解方法            在Product.java的category属性前加上@Autowired注解            @Autowired            private Category category;            或者            @Autowired            public void setCategory(Category category)         *@Resource            @Resource(name="c")            private Category category;*对bean进行注解配置    直接xml中添加  <span class="tag">&lt;<span class="name">context:component-scan</span> <span class="attr">base-package</span>=<span class="string">"pojo"</span>/&gt;</span>    就是告知spring，所有的bean都在pojo包下    通过@Component注解        在类前加入  @Component("c")  表明此类是bean        因为配置从applicationContext.xml中移出来了，所以属性初始化放在属性声明上进行了。        private String name="product 1";        private String name="category 1";        同时@Autowired也需要在Product.java的category属性前加上*Spring javaConfig 后期补充</code></pre><p><a href="https://github.com/Wangtomorrow/Spring/tree/master/spring" target="_blank" rel="noopener">源码参照</a></p><h2 id="三、面向切面（AOP）"><a href="#三、面向切面（AOP）" class="headerlink" title="三、面向切面（AOP）"></a>三、面向切面（AOP）</h2><h3 id="1-概述-1"><a href="#1-概述-1" class="headerlink" title="1.概述"></a>1.概述</h3><p>&emsp;AOP 即 Aspect Oriented Program 面向切面编程。在面向切面编程的思想里面，把功能分为 <strong>核心业务功能</strong> 和 <strong>周边功能</strong>。<br>&emsp;核心业务，比如登陆，增加数据，删除数据都叫核心业务。<br>&emsp;周边功能，比如性能统计，日志，事务管理等等。<br>&emsp;周边功能在Spring的面向切面编程AOP思想里，即被定义为 <strong>切面</strong><br>&emsp;在面向切面编程AOP的思想里面，核心业务功能和切面功能分别独立进行开发，然后把切面功能和核心业务功能 “编织” 在一起，这种能够选择性的，低耦合的把切面和核心业务功能结合在一起的编程思想，就叫AOP。  </p><h3 id="2-AOP核心概念"><a href="#2-AOP核心概念" class="headerlink" title="2.AOP核心概念"></a>2.AOP核心概念</h3><pre><code>1、横切关注点对哪些方法进行拦截，拦截后怎么处理，这些关注点称之为横切关注点2、切面（aspect）类是对物体特征的抽象，切面就是对横切关注点的抽象3、连接点（joinpoint）被拦截到的点，因为Spring只支持方法类型的连接点，所以在Spring中连接点指的就是被拦截到的方法，实际上连接点还可以是字段或者构造器4、切入点（pointcut）对连接点进行拦截的定义5、通知（advice）所谓通知指的就是指拦截到连接点之后要执行的代码，通知分为前置、后置、异常、最终、环绕通知五类6、目标对象代理的目标对象7、织入（weave）将切面应用到目标对象并导致代理对象创建的过程8、引入（introduction）在不修改代码的前提下，引入可以在运行期为类动态地添加一些方法或字段</code></pre><h3 id="3-Spring对AOP的支持"><a href="#3-Spring对AOP的支持" class="headerlink" title="3.Spring对AOP的支持"></a>3.Spring对AOP的支持</h3><p>&emsp;Spring中AOP代理由Spring的IOC容器负责生成、管理，其依赖关系也由IOC容器负责管理。因此，AOP代理可以直接使用容器中的其它bean实例作为目标，这种关系可由IOC容器的依赖注入提供。Spring创建代理的规则为：  </p><pre><code>1、默认使用Java动态代理来创建AOP代理，这样就可以为任何接口实例创建代理了2、当需要代理的类不是代理接口的时候，Spring会切换为使用CGLIB代理，也可强制使用CGLIB</code></pre><h3 id="4-AOP编程"><a href="#4-AOP编程" class="headerlink" title="4.AOP编程"></a>4.AOP编程</h3><pre><code>1、定义普通业务组件2、定义切入点，一个切入点可能横切多个业务组件 3、定义增强处理，增强处理就是在AOP框架为普通业务组件织入的处理动作</code></pre><h3 id="5-简单例子熟悉AOP"><a href="#5-简单例子熟悉AOP" class="headerlink" title="5.简单例子熟悉AOP"></a>5.简单例子熟悉AOP</h3><pre><code>AOP配置文件&lt;!--声明业务对象--&gt;    &lt;bean name=&quot;s&quot; class=&quot;service.ProductService&quot;&gt;    &lt;/bean&gt;    &lt;!--声明日志切面--&gt;    &lt;bean id=&quot;loggerAspect&quot; class=&quot;aspect.LoggerAspect&quot;/&gt;    &lt;aop:config&gt;        &lt;!--指定核心业务功能--&gt;        &lt;aop:pointcut id=&quot;loggerCutpoint&quot;                      expression=                              &quot;execution(* service.ProductService.*(..)) &quot;/&gt;    &lt;!--* 返回任意类型,   包名以 service.ProductService 开头的类的任意方法,   (..) 参数是任意数量和类型--&gt;        &lt;!--指定辅助业务功能--&gt;        &lt;aop:aspect id=&quot;logAspect&quot; ref=&quot;loggerAspect&quot;&gt;            &lt;aop:around pointcut-ref=&quot;loggerCutpoint&quot; method=&quot;log&quot;/&gt;        &lt;/aop:aspect&gt;    &lt;/aop:config&gt;</code></pre><h3 id="6-注解方式AOP"><a href="#6-注解方式AOP" class="headerlink" title="6.注解方式AOP"></a>6.注解方式AOP</h3><pre><code>1.注解注解配置业务类,使用@Component(&quot;s&quot;)2.注解配置切面    @Aspect 注解表示这是一个切面    @Component 表示这是一个bean,由Spring进行管理    @Around(value = &quot;execution(* service.ProductService.*(..))&quot;) 表示对service.ProductService 这个类中的所有方法进行切面操作3.配置applicationContext.xml    &lt;!--扫描这俩包，定位业务类和切面类--&gt;    &lt;context:component-scan base-package=&quot;aspect&quot;/&gt;    &lt;context:component-scan base-package=&quot;service&quot;/&gt;    &lt;!--找到被注解了的切面类，进行切面配置--&gt;    &lt;aop:aspectj-autoproxy/&gt;</code></pre><p><a href="https://github.com/Wangtomorrow/Spring" target="_blank" rel="noopener">源码参照</a></p><h2 id="四、总结说明"><a href="#四、总结说明" class="headerlink" title="四、总结说明"></a>四、总结说明</h2><p>&emsp;这个帖子主要就是简单的介绍了一下spring的IOC和AOP思想以及简单的例子。暂时写这么多，spring东西比较多，下一阶段应该是再看一下Spring各种注解的使用还有SpringMVC。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;最近在做后端的开发，用到了spring，借这个机会给spring捋一遍吧。东西有点多，需要点时间，抽空学。记录(一)主要是写一点spring最基础的IOC和AOP,至于spring的各种注解和SpingMVC另开贴。&lt;br&gt;
    
    </summary>
    
    
      <category term="笔记" scheme="https://wangtomorrow.github.io/tags/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="spring" scheme="https://wangtomorrow.github.io/tags/spring/"/>
    
      <category term="IOC" scheme="https://wangtomorrow.github.io/tags/IOC/"/>
    
      <category term="DI" scheme="https://wangtomorrow.github.io/tags/DI/"/>
    
      <category term="AOP" scheme="https://wangtomorrow.github.io/tags/AOP/"/>
    
  </entry>
  
  <entry>
    <title>开始吧</title>
    <link href="https://wangtomorrow.github.io/post/9f79558f.html"/>
    <id>https://wangtomorrow.github.io/post/9f79558f.html</id>
    <published>2018-09-10T10:36:06.000Z</published>
    <updated>2018-09-11T06:08:54.936Z</updated>
    
    <content type="html"><![CDATA[<p>&emsp;入职一个月了，暑假的时候来公司做实习生，目前是在做hadoop的运维和别的项目的后端开发以及一些日常琐事的处理。<br><a id="more"></a><br>&emsp;刚来的时候先是学习了hadoop的搭建，当时是搭建的Hadoop2.4版本（有时间学习一下3.0版本的新特性，自己试着搭建一下），再后来搭建了HA，加入了zookeeper。在此基础上，又学习了HDFS的机制与shell操作，yarn资源调度，还有mapreduce的工作机制，包括shuffle，partitioner，combiner等，并写了最基础的wordcount，现在做的也是mapreduce的日常运维与开发。后来又学习了hive表的机制与操作（写了好长一段时间sql语句，发现自己基础真的薄弱）。相关笔记：<a href="https://github.com/Wangtomorrow/Hadoop" target="_blank" rel="noopener">hadoop学习记录</a><br>&emsp;现在也算简单的hadoop入门了，还有公司的环境也是一个比较好的机会吧。这一个月的时间里在学习，熟悉公司业务、框架的过程中，发现了自己存在很大的问题。感觉自己涉猎过很多东西，其实真正用起来的时候发现自己其实真的是啥也会，啥也不会。说白了，还是看的多了，做的少了。<br>&emsp;最近一段时间，在做某项目的后端开发，hadoop的学习先暂告一段落了。就标记一下，hadoop接下来一段时间要学的东西吧。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">*hadoop3.0新特新及搭建</span><br><span class="line">*linux的操作，各种操作指令</span><br><span class="line">*hive表相关，涉及到sql</span><br><span class="line">*hadoop及HDFS深度学习研究</span><br><span class="line">*pig</span><br><span class="line">*hbase</span><br><span class="line">*redis</span><br><span class="line">*MongoDB</span><br><span class="line">*yarn相关细节</span><br><span class="line">*zookeeper相关细节</span><br><span class="line">*sqoop</span><br><span class="line">*Flume对比DataX</span><br><span class="line">*Spark全家桶</span><br><span class="line">*Storm对比Spark Streaming</span><br><span class="line">*kafka</span><br><span class="line">*JVM虚拟机</span><br><span class="line"></span><br><span class="line">*调度监控管理系统、数据应用等很多东西</span><br><span class="line"></span><br><span class="line">*大数据中涉及到的机器学习，Mahout、Spark MLLib等。</span><br><span class="line">（中文分词、自然语言处理、推荐算法、分类算法、回归算法、聚类算法、神经网络与深度学习）</span><br><span class="line"> 关于机器学习，可以先放一放。数学基础很重要。</span><br><span class="line"></span><br><span class="line">*会涉及到并发、多线程、负载均衡、分布式、云计算等问题。</span><br></pre></td></tr></table></figure></p><p>&emsp;关于大数据目前就想到这么多，很多东西还是得边学边加，实际项目中缺啥补啥吧。<br>&emsp;关于最近所做项目的后端，想了想，最近应该会去多学习kafka以及spring相关，可以借此机会给spring全家桶捣鼓一遍。<br>&emsp;以后大部分代码更新会在<a href="https://github.com/Wangtomorrow" target="_blank" rel="noopener">github</a>上，日常博客更新会在这里，csdn看内容吧，没营养的就不往那边整了。这边估计很少会有人看见吧，哈哈哈~~~<br>&emsp;写这个blog最初的想法，一是就当一个记事本了，记录自己学习上遇到的坑和笔记。二是为了督促和记录自己学习的。开始吧</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;emsp;入职一个月了，暑假的时候来公司做实习生，目前是在做hadoop的运维和别的项目的后端开发以及一些日常琐事的处理。&lt;br&gt;
    
    </summary>
    
    
      <category term="start" scheme="https://wangtomorrow.github.io/tags/start/"/>
    
  </entry>
  
</feed>
